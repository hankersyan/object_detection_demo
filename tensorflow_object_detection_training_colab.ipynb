{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Tony607/object_detection_demo/blob/master/tensorflow_object_detection_training_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQCnYPVDrsgx"
   },
   "source": [
    "# [How to train an object detection model easy for free](https://www.dlology.com/blog/how-to-train-an-object-detection-model-easy-for-free/) | DLology Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yhzxsJb3dpWq"
   },
   "source": [
    "## Configs and Hyperparameters\n",
    "\n",
    "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gnNXNQCjdniL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 30 17:55:38 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1070    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P0    40W /  N/A |    355MiB /  8119MiB |     19%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1388      G   /usr/lib/xorg/Xorg                166MiB |\n",
      "|    0   N/A  N/A      1562      G   ...mviewer/tv_bin/TeamViewer       11MiB |\n",
      "|    0   N/A  N/A      1631      G   /usr/bin/gnome-shell              149MiB |\n",
      "|    0   N/A  N/A      8613      G   ...token=5864789532813732051       23MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 1.x\n",
    "!nvidia-smi\n",
    "!python3 -c 'import tensorflow as tf; print(tf.__version__)'\n",
    "\n",
    "# If you forked the repository, you can replace the link.\n",
    "repo_url = 'https://github.com/hankersyan/object_detection_demo'\n",
    "\n",
    "# Number of training steps.\n",
    "num_steps = 200000 # 200000 1000\n",
    "\n",
    "# Number of evaluation steps.\n",
    "num_eval_steps = 400 # 400 20\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'rfcn_resnet101': {\n",
    "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
    "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
    "        'batch_size': 8\n",
    "    },\n",
    "    'ssd_mobilenet_v2_320x320': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'batch_size': 12\n",
    "    }\n",
    "}\n",
    "\n",
    "# Pick the model you want to use\n",
    "# Select a model in `MODELS_CONFIG`.\n",
    "selected_model = 'ssd_mobilenet_v2'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4V-XE6kbkc1"
   },
   "source": [
    "## Clone the `object_detection_demo` repository or your fork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "dxc3DmvLQF3z",
    "outputId": "61c23a22-2e27-40a3-d2b9-965e2ced3738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "/content/object_detection_demo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%cd /content\n",
    "\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "\n",
    "#!git clone {repo_url}\n",
    "%cd {repo_dir_path}\n",
    "#!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bI8__uNS8-ns"
   },
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "ecpHEnka8Kix",
    "outputId": "2d175c62-c801-4f50-813b-cb831387ba08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "/content/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "#!git clone --quiet https://github.com/tensorflow/models.git\n",
    "\n",
    "#!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "#!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "#!pip install -q pycocotools tf_slim scipy pandas\n",
    "\n",
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = ':/content/models/research/:/content/models/research/slim/:/content/models'\n",
    "\n",
    "!python3 object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-k7uGThXlny"
   },
   "source": [
    "## Prepare `tfrecord` files\n",
    "\n",
    "Use the following scripts to generate the `tfrecord` files.\n",
    "```bash\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "ezGDABRXXhPP",
    "outputId": "14197ca2-110c-419e-8a7e-60646285ade1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/object_detection_demo\n",
      "Successfully converted xml to csv.\n",
      "Generate `data/annotations/label_map.pbtxt`\n",
      "Successfully converted xml to csv.\n",
      "WARNING:tensorflow:From generate_tfrecord.py:135: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_tfrecord.py:108: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W0830 17:55:44.762694 140646743181120 module_wrapper.py:139] From generate_tfrecord.py:108: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_tfrecord.py:54: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0830 17:55:44.779556 140646743181120 module_wrapper.py:139] From generate_tfrecord.py:54: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/train.record\n",
      "WARNING:tensorflow:From generate_tfrecord.py:135: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_tfrecord.py:108: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W0830 17:55:46.551860 140313724462912 module_wrapper.py:139] From generate_tfrecord.py:108: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From generate_tfrecord.py:54: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0830 17:55:46.560676 140313724462912 module_wrapper.py:139] From generate_tfrecord.py:54: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "Successfully created the TFRecords: /content/object_detection_demo/data/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "%cd {repo_dir_path}\n",
    "\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "!python3 xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "!python3 xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "!python3 generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "!python3 generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgd-fzAIkZlV"
   },
   "outputs": [],
   "source": [
    "test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n",
    "train_record_fname = '/content/object_detection_demo/data/annotations/train.record'\n",
    "label_map_pbtxt_fname = '/content/object_detection_demo/data/annotations/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCNYAaC7w6N8"
   },
   "source": [
    "## Download base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "orDCj6ihgUMR",
    "outputId": "c6e66c92-176e-4dbf-9684-0e73b1930bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /content/models/research\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = '/content/models/research/pretrained_model'\n",
    "\n",
    "#if not (os.path.exists(MODEL_FILE)):\n",
    "#    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "#tar = tarfile.open(MODEL_FILE)\n",
    "#tar.extractall()\n",
    "#tar.close()\n",
    "\n",
    "#os.remove(MODEL_FILE)\n",
    "#if (os.path.exists(DEST_DIR)):\n",
    "#    shutil.rmtree(DEST_DIR)\n",
    "#os.rename(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "pGhvAObeiIix",
    "outputId": "7ffdf9d3-4359-4915-f34b-a70183011fbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/pretrained_model\n",
      "total 135M\n",
      "drwxrwxrwx  3 yan yan 4.0K 8月  29 15:23 .\n",
      "drwxr-xr-x 26 yan yan 4.0K 8月  30 17:47 ..\n",
      "-rwxrwxrwx  1 yan yan   77 3月  30  2018 checkpoint\n",
      "-rwxrwxrwx  1 yan yan  67M 3月  30  2018 frozen_inference_graph.pb\n",
      "-rwxrwxrwx  1 yan yan  65M 3月  30  2018 model.ckpt.data-00000-of-00001\n",
      "-rwxrwxrwx  1 yan yan  15K 3月  30  2018 model.ckpt.index\n",
      "-rwxrwxrwx  1 yan yan 3.4M 3月  30  2018 model.ckpt.meta\n",
      "-rwxrwxrwx  1 yan yan 4.2K 3月  30  2018 pipeline.config\n",
      "drwxrwxrwx  3 yan yan 4.0K 8月  29 15:23 saved_model\n"
     ]
    }
   ],
   "source": [
    "!echo {DEST_DIR}\n",
    "!ls -alh {DEST_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UHnxlfRznPP3",
    "outputId": "88c8904e-2f26-4288-f9bb-a1a4da6d1434"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/models/research/pretrained_model/model.ckpt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "fine_tune_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvwtHlLOeRJD"
   },
   "source": [
    "## Configuring a Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIhw7IdpLuiU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
    "\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fG1nCNpUXcRU"
   },
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjtCbLF2i0wI"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open(pipeline_fname, 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2490
    },
    "colab_type": "code",
    "id": "GH0MEEanocn6",
    "outputId": "a8fb1e43-21fb-43f5-e071-8575924a19a8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\r\n",
      "# Users should configure the fine_tune_checkpoint field in the train config as\r\n",
      "# well as the label_map_path and input_path fields in the train_input_reader and\r\n",
      "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\r\n",
      "# should be configured.\r\n",
      "\r\n",
      "model {\r\n",
      "  ssd {\r\n",
      "    num_classes: 3\r\n",
      "    box_coder {\r\n",
      "      faster_rcnn_box_coder {\r\n",
      "        y_scale: 10.0\r\n",
      "        x_scale: 10.0\r\n",
      "        height_scale: 5.0\r\n",
      "        width_scale: 5.0\r\n",
      "      }\r\n",
      "    }\r\n",
      "    matcher {\r\n",
      "      argmax_matcher {\r\n",
      "        matched_threshold: 0.5\r\n",
      "        unmatched_threshold: 0.5\r\n",
      "        ignore_thresholds: false\r\n",
      "        negatives_lower_than_unmatched: true\r\n",
      "        force_match_for_each_row: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    similarity_calculator {\r\n",
      "      iou_similarity {\r\n",
      "      }\r\n",
      "    }\r\n",
      "    anchor_generator {\r\n",
      "      ssd_anchor_generator {\r\n",
      "        num_layers: 6\r\n",
      "        min_scale: 0.2\r\n",
      "        max_scale: 0.95\r\n",
      "        aspect_ratios: 1.0\r\n",
      "        aspect_ratios: 2.0\r\n",
      "        aspect_ratios: 0.5\r\n",
      "        aspect_ratios: 3.0\r\n",
      "        aspect_ratios: 0.3333\r\n",
      "      }\r\n",
      "    }\r\n",
      "    image_resizer {\r\n",
      "      fixed_shape_resizer {\r\n",
      "        height: 300\r\n",
      "        width: 300\r\n",
      "      }\r\n",
      "    }\r\n",
      "    box_predictor {\r\n",
      "      convolutional_box_predictor {\r\n",
      "        min_depth: 0\r\n",
      "        max_depth: 0\r\n",
      "        num_layers_before_predictor: 0\r\n",
      "        use_dropout: false\r\n",
      "        dropout_keep_probability: 0.8\r\n",
      "        kernel_size: 1\r\n",
      "        box_code_size: 4\r\n",
      "        apply_sigmoid_to_scores: false\r\n",
      "        conv_hyperparams {\r\n",
      "          activation: RELU_6,\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 0.00004\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            truncated_normal_initializer {\r\n",
      "              stddev: 0.03\r\n",
      "              mean: 0.0\r\n",
      "            }\r\n",
      "          }\r\n",
      "          batch_norm {\r\n",
      "            train: true,\r\n",
      "            scale: true,\r\n",
      "            center: true,\r\n",
      "            decay: 0.9997,\r\n",
      "            epsilon: 0.001,\r\n",
      "          }\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    feature_extractor {\r\n",
      "      type: 'ssd_mobilenet_v2'\r\n",
      "      min_depth: 16\r\n",
      "      depth_multiplier: 1.0\r\n",
      "      conv_hyperparams {\r\n",
      "        activation: RELU_6,\r\n",
      "        regularizer {\r\n",
      "          l2_regularizer {\r\n",
      "            weight: 0.00004\r\n",
      "          }\r\n",
      "        }\r\n",
      "        initializer {\r\n",
      "          truncated_normal_initializer {\r\n",
      "            stddev: 0.03\r\n",
      "            mean: 0.0\r\n",
      "          }\r\n",
      "        }\r\n",
      "        batch_norm {\r\n",
      "          train: true,\r\n",
      "          scale: true,\r\n",
      "          center: true,\r\n",
      "          decay: 0.9997,\r\n",
      "          epsilon: 0.001,\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    loss {\r\n",
      "      classification_loss {\r\n",
      "        weighted_sigmoid {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      localization_loss {\r\n",
      "        weighted_smooth_l1 {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      hard_example_miner {\r\n",
      "        num_hard_examples: 3000\r\n",
      "        iou_threshold: 0.99\r\n",
      "        loss_type: CLASSIFICATION\r\n",
      "        max_negatives_per_positive: 3\r\n",
      "        min_negatives_per_image: 3\r\n",
      "      }\r\n",
      "      classification_weight: 1.0\r\n",
      "      localization_weight: 1.0\r\n",
      "    }\r\n",
      "    normalize_loss_by_num_matches: true\r\n",
      "    post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 1e-8\r\n",
      "        iou_threshold: 0.6\r\n",
      "        max_detections_per_class: 100\r\n",
      "        max_total_detections: 100\r\n",
      "      }\r\n",
      "      score_converter: SIGMOID\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "train_config: {\r\n",
      "  batch_size: 12\r\n",
      "  optimizer {\r\n",
      "    rms_prop_optimizer: {\r\n",
      "      learning_rate: {\r\n",
      "        exponential_decay_learning_rate {\r\n",
      "          initial_learning_rate: 0.004\r\n",
      "          decay_steps: 800720\r\n",
      "          decay_factor: 0.95\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.9\r\n",
      "      decay: 0.9\r\n",
      "      epsilon: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\r\n",
      "  fine_tune_checkpoint_type:  \"detection\"\r\n",
      "  # Note: The below line limits the training process to 200K steps, which we\r\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\r\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\r\n",
      "  # never decay). Remove the below line to train indefinitely.\r\n",
      "  num_steps: 200000\r\n",
      "  data_augmentation_options {\r\n",
      "    random_horizontal_flip {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  data_augmentation_options {\r\n",
      "    ssd_random_crop {\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "train_input_reader: {\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/content/object_detection_demo/data/annotations/train.record\"\r\n",
      "  }\r\n",
      "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\r\n",
      "}\r\n",
      "\r\n",
      "eval_config: {\r\n",
      "  num_examples: 8000\r\n",
      "  # Note: The below line limits the evaluation process to 10 evaluations.\r\n",
      "  # Remove the below line to evaluate indefinitely.\r\n",
      "  max_evals: 10\r\n",
      "}\r\n",
      "\r\n",
      "eval_input_reader: {\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/content/object_detection_demo/data/annotations/test.record\"\r\n",
      "  }\r\n",
      "  label_map_path: \"/content/object_detection_demo/data/annotations/label_map.pbtxt\"\r\n",
      "  shuffle: false\r\n",
      "  num_readers: 1\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat {pipeline_fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f11w0uO3jFCB"
   },
   "outputs": [],
   "source": [
    "model_dir = 'training/'\n",
    "# Optionally remove content in output model directory to fresh start.\n",
    "!rm -rf {model_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "23TECXvNezIF"
   },
   "source": [
    "## Run Tensorboard(Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "0H2PZs-mSCmO",
    "outputId": "468bbcb1-82ce-4e58-dff2-179ff9907d29"
   },
   "outputs": [],
   "source": [
    "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "#!unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8o6r1o5SC5M"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = model_dir\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ge1OX7gcSC7S"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5GSGxZNh8rp"
   },
   "source": [
    "### Get Tensorboard link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rjhPT9iPSJ6T",
    "outputId": "5259af87-6ae2-4461-db20-850fce5e8a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: curl: not found\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n",
      "    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDddx2rPfex9"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nC7_syR1SJ9F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6655
    },
    "colab_type": "code",
    "id": "CjDHjhKQofT5",
    "outputId": "572ae2e8-9c77-4b42-cd9a-3f987ff93d2e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W0830 17:55:51.149515 139933776000832 model_lib.py:771] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 200000\n",
      "I0830 17:55:51.149699 139933776000832 config_util.py:552] Maybe overwriting train_steps: 200000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0830 17:55:51.149810 139933776000832 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "I0830 17:55:51.149914 139933776000832 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I0830 17:55:51.150034 139933776000832 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W0830 17:55:51.150156 139933776000832 model_lib.py:787] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "I0830 17:55:51.150231 139933776000832 model_lib.py:822] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f44555d27b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "I0830 17:55:51.150530 139933776000832 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f44555d27b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f44555d68c8>) includes params argument, but params are not passed to Estimator.\n",
      "W0830 17:55:51.151107 139933776000832 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f44555d68c8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "I0830 17:55:51.151604 139933776000832 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0830 17:55:51.151773 139933776000832 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "I0830 17:55:51.152001 139933776000832 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /home/yan/.local/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0830 17:55:51.156321 139933776000832 deprecation.py:323] From /home/yan/.local/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0830 17:55:51.181030 139933776000832 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0830 17:55:51.185666 139933776000832 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0830 17:55:51.206086 139933776000832 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0830 17:56:00.171066 139933776000832 deprecation.py:323] From /content/models/research/object_detection/inputs.py:77: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0830 17:56:00.259576 139933776000832 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yan/.local/lib/python3.6/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W0830 17:56:05.452386 139933776000832 api.py:332] From /home/yan/.local/lib/python3.6/site-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0830 17:56:08.347670 139933776000832 deprecation.py:323] From /content/models/research/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0830 17:56:11.099164 139933776000832 estimator.py:1148] Calling model_fn.\n",
      "WARNING:tensorflow:From /home/yan/.local/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0830 17:56:11.324605 139933776000832 deprecation.py:323] From /home/yan/.local/lib/python3.6/site-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0830 17:56:13.327750 139933776000832 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0830 17:56:13.352070 139933776000832 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0830 17:56:13.380813 139933776000832 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0830 17:56:13.407653 139933776000832 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0830 17:56:13.434880 139933776000832 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0830 17:56:13.462904 139933776000832 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/yan/.local/lib/python3.6/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0830 17:56:16.625447 139933776000832 deprecation.py:506] From /home/yan/.local/lib/python3.6/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0830 17:56:21.421869 139933776000832 estimator.py:1150] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0830 17:56:21.422964 139933776000832 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0830 17:56:24.118595 139933776000832 monitored_session.py:240] Graph was finalized.\n",
      "2020-08-30 17:56:24.118907: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-08-30 17:56:24.147637: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799925000 Hz\n",
      "2020-08-30 17:56:24.148041: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x584ac10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-08-30 17:56:24.148081: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-08-30 17:56:24.149825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-08-30 17:56:24.234591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-08-30 17:56:24.235124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56c67f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-08-30 17:56:24.235142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070, Compute Capability 6.1\n",
      "2020-08-30 17:56:24.235320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-08-30 17:56:24.235682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.695\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-08-30 17:56:24.235886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-08-30 17:56:24.236705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-08-30 17:56:24.237435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-08-30 17:56:24.237756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-08-30 17:56:24.238818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-08-30 17:56:24.239593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-08-30 17:56:24.242558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-08-30 17:56:24.242733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-08-30 17:56:24.243154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-08-30 17:56:24.243567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-08-30 17:56:24.243663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-08-30 17:56:24.244457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-08-30 17:56:24.244470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-08-30 17:56:24.244476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-08-30 17:56:24.244587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-08-30 17:56:24.244960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-08-30 17:56:24.245284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7291 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "I0830 17:56:28.756833 139933776000832 session_manager.py:500] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0830 17:56:29.085887 139933776000832 session_manager.py:502] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
      "I0830 17:56:36.796194 139933776000832 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
      "2020-08-30 17:56:44.556873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-08-30 17:56:45.238854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "INFO:tensorflow:loss = 20.271997, step = 0\n",
      "I0830 17:56:46.380100 139933776000832 basic_session_run_hooks.py:262] loss = 20.271997, step = 0\n",
      "INFO:tensorflow:global_step/sec: 4.54719\n",
      "I0830 17:57:08.371033 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 4.54719\n",
      "INFO:tensorflow:loss = 8.904576, step = 100 (21.992 sec)\n",
      "I0830 17:57:08.371771 139933776000832 basic_session_run_hooks.py:260] loss = 8.904576, step = 100 (21.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40159\n",
      "I0830 17:57:26.884069 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.40159\n",
      "INFO:tensorflow:loss = 8.896948, step = 200 (18.513 sec)\n",
      "I0830 17:57:26.885024 139933776000832 basic_session_run_hooks.py:260] loss = 8.896948, step = 200 (18.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.39204\n",
      "I0830 17:57:45.429946 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.39204\n",
      "INFO:tensorflow:loss = 8.576221, step = 300 (18.546 sec)\n",
      "I0830 17:57:45.430607 139933776000832 basic_session_run_hooks.py:260] loss = 8.576221, step = 300 (18.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.37828\n",
      "I0830 17:58:04.023266 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.37828\n",
      "INFO:tensorflow:loss = 8.13686, step = 400 (18.593 sec)\n",
      "I0830 17:58:04.023967 139933776000832 basic_session_run_hooks.py:260] loss = 8.13686, step = 400 (18.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.4092\n",
      "I0830 17:58:22.510252 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.4092\n",
      "INFO:tensorflow:loss = 8.200121, step = 500 (18.487 sec)\n",
      "I0830 17:58:22.511086 139933776000832 basic_session_run_hooks.py:260] loss = 8.200121, step = 500 (18.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.36258\n",
      "I0830 17:58:41.158020 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.36258\n",
      "INFO:tensorflow:loss = 7.236055, step = 600 (18.648 sec)\n",
      "I0830 17:58:41.158904 139933776000832 basic_session_run_hooks.py:260] loss = 7.236055, step = 600 (18.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.38422\n",
      "I0830 17:58:59.730807 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.38422\n",
      "INFO:tensorflow:loss = 7.203757, step = 700 (18.573 sec)\n",
      "I0830 17:58:59.731498 139933776000832 basic_session_run_hooks.py:260] loss = 7.203757, step = 700 (18.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.38174\n",
      "I0830 17:59:18.312158 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.38174\n",
      "INFO:tensorflow:loss = 7.063645, step = 800 (18.581 sec)\n",
      "I0830 17:59:18.312892 139933776000832 basic_session_run_hooks.py:260] loss = 7.063645, step = 800 (18.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.40327\n",
      "I0830 17:59:36.819519 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.40327\n",
      "INFO:tensorflow:loss = 7.7706156, step = 900 (18.507 sec)\n",
      "I0830 17:59:36.820275 139933776000832 basic_session_run_hooks.py:260] loss = 7.7706156, step = 900 (18.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.34988\n",
      "I0830 17:59:55.511501 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.34988\n",
      "INFO:tensorflow:loss = 7.222143, step = 1000 (18.692 sec)\n",
      "I0830 17:59:55.512242 139933776000832 basic_session_run_hooks.py:260] loss = 7.222143, step = 1000 (18.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.37433\n",
      "I0830 18:00:14.118456 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.37433\n",
      "INFO:tensorflow:loss = 7.005536, step = 1100 (18.607 sec)\n",
      "I0830 18:00:14.119167 139933776000832 basic_session_run_hooks.py:260] loss = 7.005536, step = 1100 (18.607 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.33171\n",
      "I0830 18:00:32.874197 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.33171\n",
      "INFO:tensorflow:loss = 7.1159863, step = 1200 (18.756 sec)\n",
      "I0830 18:00:32.874864 139933776000832 basic_session_run_hooks.py:260] loss = 7.1159863, step = 1200 (18.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.22267\n",
      "I0830 18:00:52.021467 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.22267\n",
      "INFO:tensorflow:loss = 7.133439, step = 1300 (19.147 sec)\n",
      "I0830 18:00:52.022054 139933776000832 basic_session_run_hooks.py:260] loss = 7.133439, step = 1300 (19.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.25051\n",
      "I0830 18:01:11.067224 139933776000832 basic_session_run_hooks.py:692] global_step/sec: 5.25051\n",
      "INFO:tensorflow:loss = 6.542947, step = 1400 (19.046 sec)\n",
      "I0830 18:01:11.067970 139933776000832 basic_session_run_hooks.py:260] loss = 6.542947, step = 1400 (19.046 sec)\n"
     ]
    }
   ],
   "source": [
    "!python3 /content/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "KP-tUdtnRybs",
    "outputId": "effcee05-b801-442e-f4ed-1f7f13a0cf33"
   },
   "outputs": [],
   "source": [
    "!ls {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1Nrqw3nqnCh"
   },
   "outputs": [],
   "source": [
    "# Legacy way of training(also works).\n",
    "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmSESMetj1sa"
   },
   "source": [
    "## Exporting a Trained Inference Graph\n",
    "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16746
    },
    "colab_type": "code",
    "id": "DHoP90pUyKSq",
    "outputId": "3d03f9db-2ec6-4255-ee19-f2fdbd9eb66d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "!python3 /content/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "usgBZvkz0nqD",
    "outputId": "e81cb36a-316a-4ed2-f6d6-8b3501c4e204"
   },
   "outputs": [],
   "source": [
    "!ls {output_directory}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p09AOThWkaQv"
   },
   "source": [
    "## Download the model `.pb` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnDo1lonKgFr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
    "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lHqWkLBINYoI",
    "outputId": "07644b92-19df-46a3-db22-d97df933c688"
   },
   "outputs": [],
   "source": [
    "!ls -alh {pb_fname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FIqnjbWYsuQw"
   },
   "source": [
    "### Option1 : upload the `.pb` file to your Google Drive\n",
    "Then download it from your Google Drive to local file system.\n",
    "\n",
    "During this step, you will be prompted to enter the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "hAqyASIJqjae",
    "outputId": "3fcf1a18-1e27-4361-b886-5b0c71c46217"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "#!pip install -U -q PyDrive\n",
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive\n",
    "#from google.colab import auth\n",
    "#from oauth2client.client import GoogleCredentials\n",
    "\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "#auth.authenticate_user()\n",
    "#gauth = GoogleAuth()\n",
    "#gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#drive = GoogleDrive(gauth)\n",
    "\n",
    "#fname = os.path.basename(pb_fname)\n",
    "# Create & upload a text file.\n",
    "#uploaded = drive.CreateFile({'title': fname})\n",
    "#uploaded.SetContentFile(pb_fname)\n",
    "#uploaded.Upload()\n",
    "#print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FKFq8RXs6bs"
   },
   "source": [
    "### Option2 :  Download the `.pb` file directly to your local file system\n",
    "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "-bP0iMMnnr77",
    "outputId": "86ed702c-2715-46bd-8249-0e8c21ba7141"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download(pb_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFyCeiBb9BbS"
   },
   "source": [
    "### Download the `label_map.pbtxt` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1TbL6Ox8q6Z"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download(label_map_pbtxt_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUmAo9foa1xq"
   },
   "source": [
    "### Download the modified pipline file\n",
    "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pql2QpemazE1"
   },
   "outputs": [],
   "source": [
    "#files.download(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w1AgBj1l0v_W"
   },
   "outputs": [],
   "source": [
    "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
    "# from google.colab import files\n",
    "# files.download('fine_tuned_model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mz1gX19GlVW7"
   },
   "source": [
    "## Run inference test\n",
    "Test with images in repository `object_detection_demo/test` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Pzj9A4e5mj5l",
    "outputId": "5c8dcbc2-74db-4114-ed71-e66e8dfa038b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = pb_fname\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "\n",
    "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
    "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
    "\n",
    "assert os.path.isfile(pb_fname)\n",
    "assert os.path.isfile(PATH_TO_LABELS)\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
    "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
    "print(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1443
    },
    "colab_type": "code",
    "id": "CG5YUMdg1Po7",
    "outputId": "a9f78425-ce58-465f-e8c3-87c1df320d74",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%cd /content/models/research/object_detection\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "print(PATH_TO_CKPT)\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {\n",
    "                output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                        tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(\n",
    "                    tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(\n",
    "                    tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(\n",
    "                    tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
    "                                           real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
    "                                           real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(\n",
    "                output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image = Image.open(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    print(str(output_dict['num_detections']) + ' num_detections are found')\n",
    "    print(output_dict)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=10,\n",
    "        min_score_thresh=0.4,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GStNeHWPkTcN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "tensorflow-object-detection-training-colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
